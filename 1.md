# RTSP 视频流接收服务器方案书

## **项目概述**

设计并实现一个基于 FastAPI 的现代化服务端应用，用于接收和处理 SafePath Android 应用推送的 RTSP 视频流。本方案采用最新的流媒体处理技术和依赖管理实践，推荐使用 **Python 3.12**，确保与当前 Android 项目的无缝集成，同时优化性能、可维护性和部署可靠性。

## **技术栈**

* **Python 版本**: **Python 3.12** (兼顾性能、稳定性和 Debian 12 系统兼容性)  
* **后端框架**：FastAPI (异步高性能 Python Web 框架)  
* **流媒体处理**：GStreamer (推荐使用 Debian Bookworm 系统自带版本 1.22.0 以简化部署)  
* **视频处理**：OpenCV (通过 pip 安装)  
* **数据验证**: Pydantic V2 (高性能数据验证与序列化)  
* **依赖管理**: **PDM** (配合 **uv** 加速) 使用 pyproject.toml 和 pdm.lock  
* **容器化**：Docker & Docker Compose (部署与扩展)

## **与 Android 客户端的兼容性**

本方案专门针对 SafePath Android 应用的 RTSP 推流进行了优化：

* 默认监听端口配置为 554，与 Android 客户端的 RTSP\_SERVER\_URL 完全匹配  
* 支持 Android 客户端使用的 H.264 编码格式  
* 实现与 RtspCamera2 类兼容的服务端接收机制 (基于 GStreamer 1.22)   
* 处理 Android 客户端的重连逻辑

## **系统架构**

SafePath Android 客户端        GStreamer (1.22) \+ FastAPI 服务器 (Python 3.12)  
\+----------------+              \+----------------------+  
| | RTSP协议(554端口) | |  
| RtspCamera2 | \----------------\> | RTSP 接收器 |  
| (推流客户端) | | (基于GStreamer系统包) |  
\+----------------+              \+----------+-----------+  
|  
| 内部处理  
                                       v  
                               \+----------------------+  
| |  
| 视频处理模块 |  
| (GStreamer \+ OpenCV) |  
                               \+----------+-----------+  
|  
| REST API (Pydantic V2)  
                                       v  
                               \+----------------------+  
| FastAPI 接口 |  
| /status /snapshot 等 |  
                               \+----------------------+

## **功能需求**

1. **RTSP 流接收**  
   * 接收来自 Android 应用的 RTSP 流 (端口 554，路径 /live)  
   * 确保与 Android 端 RTSP\_SERVER\_URL 格式完全兼容  
   * 支持多并发连接  
2. **视频处理**  
   * 实时视频处理，支持格式转换 (基于 GStreamer 1.22)  
   * 高性能视频帧提取与保存 (使用 OpenCV)  
3. **API 接口**  
   * 连接状态监控 API  
   * 实时截图获取 (使用 Pydantic V2 进行数据校验)  
4. **状态管理**  
   * 实时监控连接状态  
   * 自动处理重连，与 Android 端的重试机制配合  
   * 详细日志记录系统

## **架构设计原则**

在设计和开发过程中，项目遵循以下架构原则，确保代码质量和可维护性：

### **1\. 模块化原则**

* 将系统拆分为独立的模块，每个模块专注于单一功能  
* 每个模块的代码量控制在300行以内，绝不超过500行  
* 模块间通过清晰定义的接口通信，避免直接修改其他模块的内部状态

### **2\. 高内聚低耦合**

* 确保每个模块/类具有明确的职责边界  
* 最小化模块间的依赖关系  
* 采用依赖注入模式传递服务和配置 (FastAPI 内建支持)

### **3\. 分层架构**

项目采用清晰的分层架构：

* **API 层**：处理 HTTP 请求和响应 (FastAPI, Pydantic V2)  
* **服务层**：实现业务逻辑  
* **基础设施层**：包括 RTSP 服务器 (GStreamer 系统包)、视频处理 (OpenCV) 等底层功能  
* **工具层**：提供通用辅助功能

## **技术实现方案**

注意：以下代码仅供参考，实际实现需确保与 Pydantic V2 和 Python 3.12 兼容。GStreamer Pipeline 可能需要根据 GStreamer 1.22 版本进行微调。

### **1\. RTSP 服务器模块 (app/rtsp/server.py)**

负责接收和处理 RTSP 视频流 (使用系统 GStreamer 库)：

Python

\# 注意：需要确保 gi 库来自系统安装的 python3-gi (for Python 3.12)  
from gi.repository import Gst, GstRtspServer, GObject  
import os  
import logging

class RtspServer:  
    def \_\_init\_\_(self, port=554, path="/live", output\_dir="./videos"):  
        self.port \= port  
        self.path \= path  
        self.output\_dir \= output\_dir  
        self.server \= None  
        self.factory \= None  
        self.log \= logging.getLogger("RtspServer")  
        \# 确保 GObject 线程初始化在应用启动时完成 (通常在 main.py)

    def initialize(self):  
        \# 初始化 GStreamer (通常在应用启动时完成)  
        \# Gst.init(None) \# 移至 main.py 启动时

        \# 创建输出目录  
        os.makedirs(self.output\_dir, exist\_ok=True)

        \# 创建RTSP服务器  
        self.server \= GstRtspServer.RTSPServer()  
        self.server.set\_service(str(self.port))

        \# 创建媒体工厂  
        self.factory \= GstRtspServer.RTSPMediaFactory()

        \# 配置流水线 (基于 GStreamer 1.22)  
        \# 接收RTSP流，将其分流为两路：一路保存为视频文件，一路用于实时处理 (通过 appsink 或类似方式传递给 OpenCV)  
        \# 注意：以下 pipeline 仅为示例，具体元素和属性需根据 GStreamer 1.22 和实际需求调整  
        \# 可能需要使用 appsink 将帧传递给 Python/OpenCV 进行处理，而不是直接用 multifilesink  
        pipeline \= (  
            "rtspsrc name=src latency=0\! rtph264depay\! h264parse\! "  
            "tee name=t "  
            \# 分支1: 保存为 MP4 文件 (示例，可能需要调整 muxer 和 sink)  
            "t.\! queue\! mp4mux\! "  
            f"filesink location={self.output\_dir}/recent.mp4 async=false "  
            \# 分支2: 解码并传递给应用处理 (示例，使用 appsink)  
            "t.\! queue\! avdec\_h264\! videoconvert\! video/x-raw,format=BGR\! "  
            "appsink name=sink emit-signals=true max-buffers=1 drop=true"  
            \# 如果仍需保存 JPEG 帧，可以从 appsink 获取帧后用 OpenCV 保存  
        )  
        self.factory.set\_launch(pipeline)  
        self.factory.set\_shared(True) \# 允许多个客户端连接到同一流

        \# 将媒体工厂与路径绑定  
        mount\_points \= self.server.get\_mount\_points()  
        mount\_points.add\_factory(self.path, self.factory)

        \# 启动服务器 (在后台线程中)  
        self.server.attach(None) \# 使用默认主循环上下文  
        self.log.info(f"RTSP服务器配置完成，将在 rtsp://0.0.0.0:{self.port}{self.path} 监听")

        \# 连接事件回调设置 (需要连接到 GstRtspServer 的信号)  
        \# self.server.connect("client-connected", self.\_on\_client\_connected\_cb)  
        \# self.factory.connect("media-configure", self.\_on\_media\_configure\_cb) \# 获取 appsink

    \# \--- 回调函数和帧处理逻辑 \---  
    \# def \_on\_client\_connected\_cb(self, server, client):  
    \#     self.log.info(f"客户端连接: {client.get\_connection().get\_ip()}")  
    \#     if hasattr(self, '\_on\_client\_connected'):  
    \#         self.\_on\_client\_connected()  
    \#     client.connect("closed", self.\_on\_client\_disconnected\_cb)

    \# def \_on\_client\_disconnected\_cb(self, client):  
    \#     self.log.info(f"客户端断开: {client.get\_connection().get\_ip()}")  
    \#     if hasattr(self, '\_on\_client\_disconnected'):  
    \#         self.\_on\_client\_disconnected()

    \# def \_on\_media\_configure\_cb(self, factory, media):  
    \#      \# 获取 pipeline 中的 appsink 元素  
    \#      pipeline \= media.get\_element()  
    \#      appsink \= pipeline.get\_by\_name('sink')  
    \#      if appsink:  
    \#          appsink.connect("new-sample", self.\_on\_new\_sample, appsink) \# 传递 appsink 实例

    \# def \_on\_new\_sample(self, appsink, user\_data):  
    \#      \# 处理从 appsink 获取的新样本 (视频帧)  
    \#      sample \= appsink.emit("pull-sample")  
    \#      if sample:  
    \#          \# 在这里将 Gst.Sample 转换为 OpenCV Mat 对象进行处理或保存  
    \#          \#... 实现 Gst Sample 到 OpenCV Mat 的转换...  
    \#          \# 例如：buffer \= sample.get\_buffer(); caps \= sample.get\_caps();...  
    \#          \# self.latest\_frame \= converted\_cv\_mat  
    \#          \# self.save\_latest\_frame\_if\_needed(converted\_cv\_mat)  
    \#          return Gst.FlowReturn.OK  
    \#      return Gst.FlowReturn.ERROR

    def set\_connection\_callbacks(self, on\_client\_connected, on\_client\_disconnected):  
        """设置客户端连接和断开的回调函数 (通过信号连接实现)"""  
        self.\_on\_client\_connected \= on\_client\_connected  
        self.\_on\_client\_disconnected \= on\_client\_disconnected  
        \# 实际连接应在 initialize 或启动时完成

    def get\_latest\_frame\_path(self) \-\> Optional\[str\]:  
        """获取最新的视频帧图像路径 (需要修改为从内存或临时文件获取)"""  
        \# 注意：原 multifilesink 方式已更改为 appsink  
        \# 需要实现从 appsink 获取帧并保存为临时文件或直接从内存返回  
        \# 以下为示例逻辑，需要替换  
        try:  
            \# 假设有一个机制将最新帧保存到特定文件 snapshot.jpg  
            latest\_frame\_file \= os.path.join(self.output\_dir, "snapshot.jpg")  
            if os.path.exists(latest\_frame\_file):  
                 return latest\_frame\_file  
            else:  
                 \# 或者查找最近的 jpg 文件 (如果采用其他保存策略)  
                 jpg\_files \= sorted(\[f for f in os.listdir(self.output\_dir) if f.endswith('.jpg')\])  
                 if jpg\_files:  
                     return os.path.join(self.output\_dir, jpg\_files\[-1\])  
                 return None  
        except Exception as e:  
            self.log.error(f"获取最新帧失败: {e}")  
            return None

### **2\. 视频处理服务 (app/services/video\_service.py)**

负责视频文件管理（主要针对录制的 MP4 文件）：

Python

import os  
import time  
import logging  
from typing import List, Optional  
from datetime import datetime

class VideoService:  
    """视频处理服务，负责视频文件管理和处理"""

    def \_\_init\_\_(self, output\_dir: str, max\_storage\_days: int \= 7):  
        """初始化视频服务

        Args:  
            output\_dir: 视频文件存储目录  
            max\_storage\_days: 视频文件保留最大天数  
        """  
        self.output\_dir \= output\_dir  
        self.max\_storage\_days \= max\_storage\_days  
        self.logger \= logging.getLogger("video\_service")

        \# 确保输出目录存在  
        os.makedirs(self.output\_dir, exist\_ok=True)

    def cleanup\_old\_videos(self) \-\> int:  
        """清理超过保留期限的视频文件 (主要针对.mp4)

        Returns:  
            int: 已清理的文件数量  
        """  
        cleaned\_count \= 0  
        try:  
            current\_time \= time.time()  
            max\_age \= self.max\_storage\_days \* 86400  \# 转换为秒

            for filename in os.listdir(self.output\_dir):  
                \# 主要清理录制的 mp4 文件  
                if filename.endswith('.mp4'):  
                    file\_path \= os.path.join(self.output\_dir, filename)  
                    \# 检查是否为文件且超过了最大存储时间  
                    if os.path.isfile(file\_path) and (current\_time \- os.path.getmtime(file\_path)) \> max\_age:  
                        os.remove(file\_path)  
                        cleaned\_count \+= 1  
                        self.logger.info(f"已清理旧 MP4 文件: {filename}")  
        except Exception as e:  
            self.logger.error(f"清理旧视频文件失败: {e}")

        return cleaned\_count

    def get\_video\_list(self) \-\> List\[str\]:  
        """获取可用的视频文件列表 (仅 MP4)

        Returns:  
            List\[str\]: 视频文件名列表  
        """  
        try:  
            return \[f for f in os.listdir(self.output\_dir) if f.endswith('.mp4')\]  
        except Exception as e:  
            self.logger.error(f"获取视频列表失败: {e}")  
            return

    def get\_video\_path(self, filename: str) \-\> Optional\[str\]:  
        """获取指定视频文件的完整路径

        Args:  
            filename: 视频文件名

        Returns:  
            Optional\[str\]: 视频文件的完整路径，如果文件不存在则返回None  
        """  
        video\_path \= os.path.join(self.output\_dir, filename)  
        return video\_path if os.path.exists(video\_path) and filename.endswith('.mp4') else None

    \# 可以增加处理从 appsink 获取的帧的函数  
    \# def process\_frame(self, frame\_data):  
    \#     \# 使用 OpenCV 处理帧，例如保存快照  
    \#     pass

### **3\. API 路由模块 (app/api/routes.py)**

负责定义和处理 API 请求 (使用 Pydantic V2 模型)：

Python

from fastapi import APIRouter, HTTPException, Depends, Response  
from fastapi.responses import FileResponse  
import base64  
from datetime import datetime  
from typing import Dict, List, Optional  
from pydantic import BaseModel, Field \# 导入 Pydantic V2

from..services.video\_service import VideoService  
from..rtsp.server import RtspServer  
from..core.config import get\_settings

router \= APIRouter()

\# 使用 Pydantic V2 定义响应模型  
class ServerStatus(BaseModel):  
    is\_running: bool  
    start\_time: Optional\[datetime\] \= None  
    connections: int \= 0  
    last\_frame\_time: Optional\[datetime\] \= None  
    server\_ip: Optional\[str\] \= None

class StatusResponse(BaseModel):  
    status: ServerStatus  
    rtsp\_url: str

class SnapshotResponse(BaseModel):  
    image\_base64: str

class VideoListResponse(BaseModel):  
    videos: List\[str\]

class HealthResponse(BaseModel):  
    status: str \= "ok"

\# 状态信息 (应考虑使用更健壮的状态管理机制，例如类或依赖注入)  
server\_status\_data \= {  
    "is\_running": False,  
    "start\_time": None,  
    "connections": 0,  
    "last\_frame\_time": None,  
    "server\_ip": None  
}

\# 依赖注入函数 (假设在 main.py 或其他地方定义和实例化)  
def get\_rtsp\_server() \-\> RtspServer:  
    \# Placeholder: 实际应返回全局或请求作用域的 RtspServer 实例  
    from..main import rtsp\_server \# 示例：从 main 导入  
    return rtsp\_server

def get\_video\_service() \-\> VideoService:  
    \# Placeholder: 实际应返回全局或请求作用域的 VideoService 实例  
    from..main import video\_service \# 示例：从 main 导入  
    return video\_service

@router.get("/status", response\_model=StatusResponse)  
async def get\_status() \-\> StatusResponse:  
    """获取RTSP服务器状态"""  
    settings \= get\_settings()  
    status \= ServerStatus(\*\*server\_status\_data) \# 使用 Pydantic 模型验证/转换  
    rtsp\_url \= f"rtsp://{status.server\_ip or 'localhost'}:{settings.RTSP\_PORT}{settings.RTSP\_PATH}"  
    return StatusResponse(status=status, rtsp\_url=rtsp\_url)

@router.get("/snapshot")  
async def get\_snapshot(  
    as\_file: bool \= False,  
    rtsp\_server: RtspServer \= Depends(get\_rtsp\_server)  
) \-\> Response: \# 返回通用 Response 以支持 FileResponse 或 JSON  
    """获取当前视频帧截图"""  
    if not server\_status\_data\["is\_running"\]:  
        raise HTTPException(status\_code=503, detail="RTSP服务未运行")

    frame\_path \= rtsp\_server.get\_latest\_frame\_path()  
    if not frame\_path or not os.path.exists(frame\_path):  
        raise HTTPException(status\_code=404, detail="没有可用的视频帧")

    \# 更新最后帧时间 (注意线程安全，如果状态被多线程访问)  
    server\_status\_data\["last\_frame\_time"\] \= datetime.now()

    if as\_file:  
        return FileResponse(frame\_path, media\_type="image/jpeg", filename="snapshot.jpg")  
    else:  
        try:  
            with open(frame\_path, "rb") as image\_file:  
                encoded\_string \= base64.b64encode(image\_file.read()).decode()  
            \# 返回符合 Pydantic V2 模型的 JSON 响应  
            return SnapshotResponse(image\_base64=encoded\_string)  
        except Exception as e:  
             logging.getLogger("api").error(f"读取或编码快照失败: {e}")  
             raise HTTPException(status\_code=500, detail="无法处理快照图像")

@router.get("/videos", response\_model=VideoListResponse)  
async def list\_videos(  
    video\_service: VideoService \= Depends(get\_video\_service)  
) \-\> VideoListResponse:  
    """获取可用的视频片段列表 (MP4)"""  
    return VideoListResponse(videos=video\_service.get\_video\_list())

@router.get("/video/{filename}")  
async def get\_video(  
    filename: str,  
    video\_service: VideoService \= Depends(get\_video\_service)  
) \-\> FileResponse:  
    """获取特定的视频片段文件 (MP4)"""  
    video\_path \= video\_service.get\_video\_path(filename)  
    if not video\_path:  
        raise HTTPException(status\_code=404, detail="视频文件不存在或非 MP4 文件")

    return FileResponse(  
        video\_path,  
        media\_type="video/mp4",  
        filename=filename  
    )

@router.get("/health", response\_model=HealthResponse)  
async def health\_check() \-\> HealthResponse:  
    """健康检查，用于监控和负载均衡"""  
    return HealthResponse(status="ok")

\# \--- 辅助函数更新状态 (需要考虑线程安全) \---  
def update\_server\_status(key: str, value: any):  
    \# 注意：直接修改全局字典在多线程/多进程环境下不安全  
    \# 应使用线程安全的结构或状态管理模式  
    server\_status\_data\[key\] \= value

def increment\_connection\_count():  
    \# 同上，需要线程安全  
    server\_status\_data\["connections"\] \+= 1  
    logging.getLogger("api").info(f"当前连接数: {server\_status\_data\['connections'\]}")

def decrement\_connection\_count():  
    \# 同上，需要线程安全  
    server\_status\_data\["connections"\] \-= 1  
    logging.getLogger("api").info(f"当前连接数: {server\_status\_data\['connections'\]}")

### **4\. 主应用模块 (app/main.py)**

整合所有组件并启动应用：

Python

from fastapi import FastAPI  
from fastapi.middleware.cors import CORSMiddleware  
import threading  
import socket  
from datetime import datetime  
import logging  
import asyncio  
import signal

\# 导入 GObject 和 GStreamer (确保来自系统安装)  
from gi.repository import GObject, Gst

from.api.routes import router as api\_router, update\_server\_status, increment\_connection\_count, decrement\_connection\_count  
from.rtsp.server import RtspServer  
from.services.video\_service import VideoService  
from.core.config import get\_settings  
from.core.logger import setup\_logging

\# 配置日志  
logger \= setup\_logging()

\# 初始化 GStreamer 和 GObject 线程  
GObject.threads\_init()  
Gst.init(None)

app \= FastAPI(title="SafePath RTSP Receiver (Optimized)")

\# 导入设置  
settings \= get\_settings()

\# 启用CORS  
app.add\_middleware(  
    CORSMiddleware,  
    allow\_origins=\["\*"\], \# 生产环境应配置具体来源  
    allow\_credentials=True,  
    allow\_methods=\["\*"\],  
    allow\_headers=\["\*"\],  
)

\# 注册API路由  
app.include\_router(api\_router)

\# 实例化服务 (全局实例，注意线程安全和状态管理)  
rtsp\_server \= RtspServer(  
    port=settings.RTSP\_PORT,  
    path=settings.RTSP\_PATH,  
    output\_dir=settings.OUTPUT\_DIR  
)

video\_service \= VideoService(  
    output\_dir=settings.OUTPUT\_DIR,  
    max\_storage\_days=settings.MAX\_VIDEO\_STORAGE\_DAYS  
)

\# GObject 主循环  
mainloop \= GObject.MainLoop()

\# 获取服务器IP地址  
def get\_server\_ip():  
    try:  
        \# 尝试连接到一个外部地址来获取本机用于外网通信的 IP  
        s \= socket.socket(socket.AF\_INET, socket.SOCK\_DGRAM)  
        s.connect(("8.8.8.8", 80)) \# 连接 Google DNS (不会实际发送数据)  
        ip\_address \= s.getsockname()  
        s.close()  
        return ip\_address  
    except Exception as e:  
        logger.warning(f"无法自动检测外部 IP 地址: {e}. 回退到 hostname.")  
        try:  
            \# 回退到获取主机名对应的 IP (可能只是内网 IP)  
            hostname \= socket.gethostname()  
            ip\_address \= socket.gethostbyname(hostname)  
            return ip\_address  
        except Exception as e\_inner:  
            logger.error(f"获取服务器 IP 地址失败: {e\_inner}")  
            return "0.0.0.0" \# 返回默认值

\# 启动 RTSP 服务器的后台任务 (运行 GObject MainLoop)  
def run\_rtsp\_server\_loop():  
    try:  
        rtsp\_server.initialize()  
        \# 设置连接回调 (需要确保 RtspServer 内部正确连接了信号)  
        rtsp\_server.set\_connection\_callbacks(  
            on\_client\_connected=increment\_connection\_count,  
            on\_client\_disconnected=decrement\_connection\_count  
        )  
        update\_server\_status("is\_running", True)  
        update\_server\_status("start\_time", datetime.now())  
        update\_server\_status("server\_ip", get\_server\_ip())  
        logger.info("RTSP 服务器初始化完成，启动 GObject 主循环...")  
        mainloop.run() \# 阻塞直到 mainloop.quit() 被调用  
    except Exception as e:  
        logger.error(f"启动或运行 RTSP 服务器 GObject 主循环失败: {e}", exc\_info=True)  
        update\_server\_status("is\_running", False)  
    finally:  
        logger.info("GObject 主循环已退出。")

\# 定期执行的后台任务 (使用 asyncio)  
async def periodic\_tasks():  
    while True:  
        try:  
            logger.info("开始执行定期清理任务...")  
            \# 在异步任务中运行同步阻塞代码  
            files\_cleaned \= await asyncio.to\_thread(video\_service.cleanup\_old\_videos)  
            logger.info(f"清理了 {files\_cleaned} 个过期视频文件")  
        except Exception as e:  
            logger.error(f"定期清理任务失败: {e}", exc\_info=True)  
        \# 每天执行一次清理 (86400 秒)  
        await asyncio.sleep(86400)

\# 优雅关闭处理  
async def shutdown\_event():  
    logger.info("收到关闭信号，开始优雅关闭...")  
    if mainloop.is\_running():  
        logger.info("正在停止 GObject 主循环...")  
        mainloop.quit()  
    \# 等待 RTSP 服务器线程结束 (如果需要)  
    if rtsp\_thread and rtsp\_thread.is\_alive():  
         logger.info("等待 RTSP 服务器线程退出...")  
         rtsp\_thread.join(timeout=5) \# 等待最多 5 秒  
         if rtsp\_thread.is\_alive():  
              logger.warning("RTSP 服务器线程未在超时内退出。")  
    \# 取消定期任务  
    if periodic\_task:  
        logger.info("正在取消定期任务...")  
        periodic\_task.cancel()  
        try:  
            await periodic\_task  
        except asyncio.CancelledError:  
            logger.info("定期任务已取消。")  
    logger.info("关闭完成。")

rtsp\_thread \= None  
periodic\_task \= None

@app.on\_event("startup")  
async def startup\_event():  
    global rtsp\_thread, periodic\_task  
    logger.info("应用启动，正在初始化...")

    \# 在单独线程中启动 GObject 主循环以运行 RTSP 服务器  
    rtsp\_thread \= threading.Thread(target=run\_rtsp\_server\_loop, daemon=True)  
    rtsp\_thread.start()

    \# 启动定期任务  
    periodic\_task \= asyncio.create\_task(periodic\_tasks())

    logger.info("应用启动完成。")

@app.on\_event("shutdown")  
async def shutdown\_app():  
    await shutdown\_event()

\# 添加信号处理以支持优雅关闭 (uvicorn 会处理 SIGINT/SIGTERM)  
\# 但如果直接运行 Python 脚本，可能需要手动添加  
\# signal.signal(signal.SIGINT, lambda s, f: asyncio.create\_task(shutdown\_event()))  
\# signal.signal(signal.SIGTERM, lambda s, f: asyncio.create\_task(shutdown\_event()))

\# \--- 服务注入函数 (用于 FastAPI Depends) \---  
\# 这些函数现在可以直接返回全局实例  
\# 注意：如果未来需要更复杂的依赖管理（如请求作用域），则需要调整  
def get\_rtsp\_server\_instance() \-\> RtspServer:  
    return rtsp\_server

def get\_video\_service\_instance() \-\> VideoService:  
    return video\_service

\# 更新 API 路由中的依赖项以使用这些新函数名  
\# (在 routes.py 中: Depends(get\_rtsp\_server\_instance), Depends(get\_video\_service\_instance))

## **优化的项目目录结构 (使用 PDM)**

src/  
├── app/                      \# 应用程序主目录  
│   ├── \_\_init\_\_.py  
│   ├── main.py               \# 主应用入口 (FastAPI app)  
│   ├── api/                  \# API层  
│   │   ├── \_\_init\_\_.py  
│   │   ├── routes.py         \# API路由定义  
│   │   └── models.py         \# Pydantic V2 API数据模型 (可选, 可放在 routes.py 或单独文件)  
│   ├── core/                 \# 核心配置  
│   │   ├── \_\_init\_\_.py  
│   │   ├── config.py         \# 应用配置 (Pydantic Settings)  
│   │   └── logger.py         \# 日志配置  
│   ├── rtsp/                 \# RTSP相关模块  
│   │   ├── \_\_init\_\_.py  
│   │   └── server.py         \# RTSP服务器核心 (使用系统 GStreamer)  
│   ├── services/             \# 服务层  
│   │   ├── \_\_init\_\_.py  
│   │   ├── video\_service.py  \# 视频处理服务  
│   │   ├── ai\_processor.py   \# AI 处理服务 (Roboflow InferencePipeline)  
│   │   ├── processors.py     \# 处理器基类和工具  
│   │   └── monitor.py        \# 性能监控服务  
│   ├── websockets/           \# WebSocket 相关模块 (新增)  
│   │   ├── \_\_init\_\_.py  
│   │   └── manager.py        \# WebSocket 连接管理器  
│   └── utils/                \# 工具函数  
│       ├── \_\_init\_\_.py  
│       └── helpers.py        \# 辅助函数  
├── videos/                   \# 视频存储目录 (运行时创建)  
├── tests/                    \# 测试代码  
│   ├── \_\_init\_\_.py  
│   ├── test\_api.py           \# API测试  
│   ├── test\_ai\_processor.py  \# AI处理器测试  
│   └── test\_video\_service.py \# 视频服务测试  
├── docker/                   \# Docker相关  
│   ├── Dockerfile            \# 优化后的 Dockerfile  
│   └── docker-compose.yml    \# Docker Compose 配置  
├──.github/                  \# GitHub 相关配置 (可选)  
│   └── workflows/            \# CI/CD 工作流 (可选)  
├── pyproject.toml            \# PDM 配置文件 (替代 requirements.txt)  
├── pdm.lock                  \# PDM 锁文件 (确保依赖一致性)  
└── README.md                 \# 项目说明 (包含系统依赖列表)

## **部署方案**

项目使用 Docker 进行容器化部署，确保环境一致性和简化部署流程。依赖管理使用 PDM。

### **pyproject.toml (示例)**

Ini, TOML

\[project\]  
name \= "rtsp-receiver-service"  
version \= "0.1.0"  
description \= "RTSP Video Stream Receiver Service using FastAPI and GStreamer"  
authors \= \[  
    {name \= "Your Name", email \= "your.email@example.com"},  
\]  
dependencies \= \[  
    "fastapi\[standard\]~=0.110.0",       \# 调整版本兼容 Roboflow inference 库  
    "uvicorn\[standard\]\>=0.34.0,\<0.35.0",   \# 明确指定以获取标准性能库  
    "pydantic\>=2.11.0,\<3.0.0",  
    "opencv-python==4.10.0.84",           \# 固定版本以确保兼容性  
    "python-dotenv\>=1.0.0",  
    "pydantic-settings~=2.7.0",           \# 用于配置管理  
    "python-multipart\>=0.0.9",           \# 用于处理表单数据和文件上传  
    "websockets\>=12.0.0",                \# WebSocket 服务器 
    "roboflow\>=1.1.63",                  \# Roboflow 客户端  
    "inference\>=0.49.1",                 \# Roboflow InferencePipeline  
    "supervision\>=0.25.1",               \# 用于视觉分析和标注  
    "numpy~=2.0.0",                       \# 兼容 inference  
    "pandas\>=2.0.0",                     \# 用于数据处理  
    \# PyGObject 和 GStreamer 通过系统包安装，不在此列出  
\]  
requires-python \= "\>=3.12,\<3.13" \# 明确指定 Python 3.12

\[project.optional-dependencies\]  
dev \= \[  
    "pytest\>=7.0.0",  
    "httpx\>=0.25.0", \# 用于异步 API 测试  
\]

\[build-system\]  
requires \= \["pdm-backend"\]  
build-backend \= "pdm.backend"

\[tool.pdm\]  
\# PDM 配置，例如使用 uv  
\[tool.pdm.tool-options\]  
use\_uv \= true

\[tool.pdm.dev-dependencies\]  
\# 开发依赖也可以放在这里  
dev \= \[  
    "pytest\>=7.0.0",  
    "httpx\>=0.25.0",  
\]

### **Docker Compose 配置 (docker/docker-compose.yml)**

YAML

version: '3.8' \# 使用较新版本

services:  
  rtsp-server:  
    build:  
      context:..  
      dockerfile: docker/Dockerfile  
    ports:  
      \- "8000:8000"   \# FastAPI API端口  
      \- "8765:8765"   \# WebSocket 端口  
      \- "554:554/tcp" \# RTSP TCP 端口  
      \# RTSP 可能还需要 UDP 端口，范围取决于 GStreamer 配置  
      \# \- "5000-5010:5000-5010/udp" \# 示例 UDP 端口范围  
    volumes:  
      \-../videos:/app/videos \# 挂载视频存储目录  
    restart: unless-stopped  
    environment:  
      \# 基本配置  
      \- RTSP\_PORT=554  
      \- RTSP\_PATH=/live  
      \- OUTPUT\_DIR=/app/videos  
      \- MAX\_VIDEO\_STORAGE\_DAYS=7  
      \# AI 处理相关配置  
      \- ROBOFLOW\_API\_KEY=your_roboflow_api_key  
      \- ROBOFLOW\_MODEL\_ID=next-level-i0lpn/3  
      \- ROBOFLOW\_CONFIDENCE\_THRESHOLD=0.7  
      \- ENABLE\_AI\_PROCESSING=true  
      \# WebSocket 相关配置  
      \- WEBSOCKET\_PORT=8765  
      \- MAX\_FPS=10  
      \# 调试配置  
      \# \- GST\_DEBUG=2
      \- LOG\_LEVEL=info  
      \# GStreamer 相关环境变量 (可选)  
      \# \- GST\_DEBUG=2  
    healthcheck:  
      test: \["CMD", "curl", "-f", "http://localhost:8000/health"\]  
      interval: 30s  
      timeout: 10s  
      retries: 3  
      start\_period: 30s \# 给应用启动留出时间

### **Dockerfile (docker/Dockerfile)**

Dockerfile

\# 使用与 Debian Bookworm 匹配的 Python 3.12 基础镜像  
FROM python:3.12\-slim-bookworm

WORKDIR /app

\# 设置推荐的 PDM 版本和 pipx (用于安装 PDM)  
ENV PDM\_VERSION=2.15.4 \\  
    PIPX\_HOME=/opt/pipx \\  
    PIPX\_BIN\_DIR=/usr/local/bin  
ENV PATH="${PATH}:${PIPX\_BIN\_DIR}"

\# 安装 pipx 和 PDM  
RUN apt-get update && apt-get install \-y \--no-install-recommends \\  
    pipx \\  
    git \\  
    build-essential \\ 
    pkg-config \\  
    libcairo2-dev \\  
    libgirepository1.0-dev \\  
    && pipx install pdm==${PDM\_VERSION} \\  
    && apt-get purge \-y \--auto-remove \\  
    && rm \-rf /var/lib/apt/lists/\*

\# 安装系统依赖 (基于 Debian Bookworm 的 GStreamer 1.22)  
\# 包含核心库、插件、RTSP 服务器、Python 绑定和 GI 数据  
RUN apt-get update && apt-get install \-y \--no-install-recommends \\  
    \# GStreamer 核心和插件  
    gstreamer1.0\-tools \\  
    gstreamer1.0\-plugins-base \\  
    gstreamer1.0\-plugins-good \\  
    gstreamer1.0\-plugins-bad \\  
    gstreamer1.0\-plugins-ugly \\  
    gstreamer1.0\-libav \\  
    \# RTSP 服务器  
    gstreamer1.0\-rtsp \\  
    libgstrtspserver-1.0\-0 \\  
    \# Python 绑定和 GObject Introspection 数据  
    python3-gi \\  
    gir1.2\-glib-2.0 \\  
    gir1.2\-gobject-2.0 \\  
    gir1.2\-gst-plugins-base-1.0 \\  
    gir1.2\-gstreamer-1.0 \\  
    \# OpenCV 运行时依赖 (部分可能已包含)  
    libglib2.0\-0 \\  
    libsm6 \\  
    libxext6 \\  
    libxrender1 \\  
    \# 其他工具  
    curl \\  
    \# 清理  
    && apt-get clean \\  
    && rm \-rf /var/lib/apt/lists/\*

\# 设置 Python 环境变量  
ENV PYTHONUNBUFFERED=1 \\  
    \# PYTHONPATH 可能不需要，PDM 会处理虚拟环境  
    \# PYTHONPATH=/app  
    \# GStreamer 调试级别 (可选)  
    GST\_DEBUG=2

\# 复制 PDM 配置文件  
COPY pyproject.toml pdm.lock./

\# 安装项目依赖 (使用 PDM 和 uv)  
\# \--prod 表示只安装生产依赖  
\# \--no-editable 表示不以可编辑模式安装  
RUN pdm install \--prod \--no-editable

\# 创建视频存储目录并设置权限  
RUN mkdir \-p /app/videos && chmod 777 /app/videos

\# 复制应用代码  
\# 注意：如果项目结构是 src/app，需要调整 COPY 命令  
\# 假设代码在 src/ 目录下  
COPY./src/app /app/app  
\# 如果 main.py 在 src/ 下，则 COPY./src /app

\# 暴露 FastAPI 端口  
EXPOSE 8000  
\# 暴露 RTSP 端口 (TCP)  
EXPOSE 554  
\# 暴露 WebSocket 端口  
EXPOSE 8765

\# 启动命令 (使用 uvicorn 运行 FastAPI 应用)  
\# 注意：如果 main.py 在 app/ 目录下，则为 app.main:app  
CMD \["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"\]

## **与 Android 客户端的兼容细节**

为确保与 SafePath Android 客户端的无缝兼容，我们进行了以下特定设计：

1. **URL 格式匹配**：  
   * 服务器监听端口 554（标准 RTSP 端口）  
   * 路径设置为 "/live"，与 Android 端的 RTSP\_SERVER\_URL 相匹配  
2. **错误处理协调**：  
   * 服务器能够识别和响应 Android 客户端的连接尝试  
   * 支持客户端的重试机制，在连接中断后可快速重建连接  
3. **编码兼容性**：  
   * GStreamer 配置支持 H.264 视频编码，与 Android 客户端默认使用的编码格式兼容  
   * 处理 RTP 封包，正确解析 Android 推流的数据 (由 GStreamer 处理)  
4. **状态监控**：  
   * 提供 /status API，可用于向 Android 客户端反馈连接情况  
   * 提供 /health 健康检查端点，便于监控服务是否正常运行

## **性能与资源优化**

1. **流媒体处理优化**：  
   * 使用 GStreamer (系统优化版本 1.22) 进行流处理。  
   * Pipeline 设计考虑使用 appsink 高效传递帧到应用层进行处理。  
2. **资源管理**：  
   * 自动清理旧的视频文件 (.mp4)，防止磁盘空间耗尽。  
   * 使用 Python 3.12 和 Pydantic V2 获得更好的内存和 CPU 效率。  
   * 容器化部署限制资源使用。  
3. **高并发支持**：  
   * FastAPI 和 Uvicorn 提供异步处理能力，支持多客户端同时连接。  
   * GStreamer RTSPMediaFactory 设置为 shared=True 以支持多客户端访问同一流。

## **验收标准**

1. 服务器能成功接收 SafePath Android 应用的 RTSP 流 (H.264)。  
2. 在 Android 客户端设置 RTSP\_SERVER\_URL 后，可一键连接成功。  
3. 连接断开后，能配合 Android 客户端的重试机制自动重连。  
4. API 接口 (/status, /snapshot) 响应时间小于 100ms (在合理负载下)。  
5. 支持至少 10 个并发 RTSP 连接 (需进行压力测试验证)。  
6. 视频帧处理延迟（从接收到 API 可获取快照）小于 500ms (需测试验证)。

## **开发与测试计划**

1. **阶段一**：环境与基础框架搭建  
   * 配置 PDM 和 Python 3.12 开发环境。  
   * 搭建 Docker 环境，安装系统 GStreamer 1.22 和 Python 绑定。  
   * 实现基础 GStreamer RTSP 服务器逻辑 (使用 appsink)。  
   * 与 Android 客户端进行初步连接和流接收测试。  
2. **阶段二**：API 与核心功能实现  
   * 开发 FastAPI 接口 (使用 Pydantic V2 模型)。  
   * 实现从 appsink 获取视频帧并使用 OpenCV 处理/保存快照的逻辑。  
   * 实现 MP4 文件录制和管理 (VideoService)。  
3. **阶段三**：集成与测试  
   * 实现状态监控和连接回调逻辑。  
   * 编写单元测试和集成测试 (使用 pytest 和 httpx)。  
   * 与 Android 客户端进行完整流程测试，包括重连。  
4. **阶段四**：优化与部署  
   * 性能调优 (GStreamer pipeline, 异步代码)。  
   * 完善 Dockerfile 和 Docker Compose 配置。  
   * 部署到测试/生产环境，添加日志和监控。

## **未来扩展方向**

1. **视频分析功能**：  
   * 在 appsink 的回调中使用 OpenCV 或其他 AI 库进行实时分析 (物体识别、动作检测等)。  
2. **云存储集成**：  
   * 将录制的 MP4 文件或关键帧自动上传到云存储服务 (S3, Google Cloud Storage 等)。  
3. **多路 RTSP 支持**：  
   * 扩展 RTSP 服务器以支持动态创建或管理多个不同的 RTSP 流路径。  
4. **WebRTC 直播**：  
   * 添加 WebRTC 支持，允许浏览器直接低延迟观看直播流。  
5. **管理界面**：  
   * 开发一个简单的 Web UI 用于查看状态、管理录制的视频等。

## **总结**

本方案采纳了 **Python 3.12**、**Pydantic V2** 和 **PDM** 等现代化工具和实践，旨在提升 RTSP 视频流接收服务器的性能、可维护性和部署可靠性。通过推荐使用 Debian Bookworm 系统自带的 **GStreamer 1.22** 版本，简化了复杂系统依赖的管理。方案强调了**容器化 (Docker)** 的重要性，并提供了更新的 pyproject.toml、Dockerfile 和 docker-compose.yml 配置示例。

系统集成了 **Roboflow InferencePipeline** 用于实时 AI 处理，能够对视频流进行盲道检测分析，并通过 **WebSocket** 实时将结构化的检测结果推送至客户端应用。这种实时数据传输架构让系统能够与 Android 客户端进行高效通信，满足用户在行走过程中对实时盲道检测的需求。

代码实现采用模块化设计，通过清晰的依赖注入和异步处理提高系统性能和可靠性。方案提供了面向生产环境的完整配置和部署指南，简化了系统上线流程。该方案在满足核心需求的同时，为未来的功能扩展如更多 AI 模型集成、实时警报等功能奠定了坚实的基础。

## **AI 视频流处理与 WebSocket 数据传输**

### **Roboflow InferencePipeline 集成**

本方案集成了 Roboflow 的 InferencePipeline 组件，用于对 RTSP 视频流进行实时 AI 分析。InferencePipeline 是 Roboflow Inference 库中专为处理流式视频数据设计的核心组件，采用异步方式处理视频源，能够高效地分析来自 RTSP 流的数据。

#### **AI 处理架构**

`app/services/ai_processor.py` 模块实现了 AIProcessor 类，封装了 Roboflow InferencePipeline 的功能：

```python
class AIProcessor:
    """
    封装 Roboflow InferencePipeline，用于处理视频帧并进行 AI 分析。
    """

    def __init__(
        self,
        model_id: str,
        rtsp_url: str,
        on_prediction_callback: Callable[[Dict[str, Any]], Coroutine[Any, Any, None]],
        api_key: Optional[str] = None,
    ):
        """
        初始化 AIProcessor。

        Args:
            model_id: Roboflow 模型 ID
            rtsp_url: RTSP 视频流地址
            on_prediction_callback: 异步回调函数，用于处理每帧的推理结果
            api_key: Roboflow API 密钥
        """
        # 初始化成员变量...
        
        # 初始化 Roboflow 推理管道
        self.inference_pipeline = InferencePipeline.init(
            model_id=self.model_id,
            video_reference=self.rtsp_url,  # 设置视频源
            api_key=self.api_key,
            confidence=settings.ROBOFLOW_CONFIDENCE_THRESHOLD,
            on_prediction=self._on_prediction
        )
```

#### **预测结果处理**

AI 处理器实现了 `_on_prediction` 回调函数，在每次模型推理完成后被调用。该函数解析模型输出结果，并将其转换为统一的 JSON 格式：

```python
def _on_prediction(self, predictions: Any, video_frame: Any) -> None:
    """
    处理 Roboflow 推理结果的回调函数

    Args:
        predictions: 模型推理结果
        video_frame: 视频帧数据
    """
    # 处理检测结果
    detections = []
    if hasattr(predictions, "predictions"):
        raw_detections = predictions.predictions
    elif isinstance(predictions, list):
        raw_detections = predictions
    else:
        raw_detections = [predictions]

    # 处理每个检测结果
    for det in raw_detections:
        if not det:
            continue

        detection_data = {
            "class": det.get("class", "unknown"),
            "confidence": float(det.get("confidence", 0.0)),
            "x_center": float(det.get("x", 0.0)),
            "y_center": float(det.get("y", 0.0)),
            "width": float(det.get("width", 0.0)),
            "height": float(det.get("height", 0.0))
        }
        detections.append(detection_data)

    # 构建输出数据
    processed_data = {
        "frame_id": self.frame_count,
        "timestamp": int(asyncio.get_event_loop().time() * 1000),
        "fps": round(current_fps, 2),
        "detections": detections
    }
    
    # 通过异步回调发送处理结果
    if self.loop:
        asyncio.run_coroutine_threadsafe(
            self.on_prediction_callback(processed_data),
            self.loop
        )
```

### **WebSocket 数据传输**

为了实现与客户端的实时数据传输，系统集成了 WebSocket 服务器，能够将 AI 处理结果实时推送给订阅的客户端（如 Android 应用）。

#### **WebSocket 连接管理**

`app/websockets/manager.py` 模块实现了 WebSocket 连接管理器：

```python
class WebSocketManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        
    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
        
    async def broadcast(self, message: Dict[str, Any]):
        """向所有活跃连接广播消息"""
        disconnected = []
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception:
                disconnected.append(connection)
                
        # 移除断开的连接
        for connection in disconnected:
            self.disconnect(connection)
```

#### **WebSocket 路由**

在 FastAPI 应用中添加 WebSocket 路由处理连接请求：

```python
# 在 app/api/routes.py 中添加

from fastapi import APIRouter, WebSocket, Depends
from app.websockets.manager import WebSocketManager

router = APIRouter()
websocket_manager = WebSocketManager()

@router.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket 连接端点，用于实时推送 AI 检测结果"""
    await websocket_manager.connect(websocket)
    try:
        # 保持连接，直到客户端断开
        while True:
            # 可选：接收客户端消息
            data = await websocket.receive_text()
            # 处理来自客户端的消息...
    except Exception as e:
        # 处理连接断开
        websocket_manager.disconnect(websocket)
```

#### **AI 结果推送**

AI 处理结果通过 WebSocket 广播给所有连接的客户端：

```python
# 在 AI 处理服务中定义推送函数

async def broadcast_ai_results(prediction_data: Dict[str, Any]):
    """将 AI 检测结果广播给所有 WebSocket 客户端"""
    await websocket_manager.broadcast(prediction_data)
```

### **数据格式规范**

系统采用标准化的 JSON 格式在服务端和客户端之间传输数据：

```json
{
  "frame_id": 1234,
  "timestamp": 1684036923456,
  "fps": 8.5,
  "detections": [
    {
      "class": "tactile_paving",
      "confidence": 0.95,
      "x_center": 320.5,
      "y_center": 240.3,
      "width": 100.0,
      "height": 50.0
    },
    // 可能有多个检测结果...
  ]
}
```

### **服务启动流程**

在应用启动时，AI 处理器和 WebSocket 服务器一起被初始化和启动：

```python
# 在 app/main.py 中

@app.on_event("startup")
async def startup_event():
    global rtsp_thread, periodic_task, ai_processor
    logger.info("应用启动，正在初始化...")

    # 在单独线程中启动 GObject 主循环以运行 RTSP 服务器
    rtsp_thread = threading.Thread(target=run_rtsp_server_loop, daemon=True)
    rtsp_thread.start()

    # 启动定期任务
    periodic_task = asyncio.create_task(periodic_tasks())

    # 如果启用 AI 处理，初始化 AI 处理器
    if settings.ENABLE_AI_PROCESSING:
        ai_processor = AIProcessor(
            model_id=settings.ROBOFLOW_MODEL_ID,
            rtsp_url=f"rtsp://127.0.0.1:{settings.RTSP_PORT}{settings.RTSP_PATH}",
            on_prediction_callback=broadcast_ai_results,
            api_key=settings.ROBOFLOW_API_KEY
        )
        await ai_processor.start()
        logger.info("AI 处理器已启动")

    logger.info("应用启动完成。")
```

### **扩展配置选项**

在 `app/core/config.py` 中添加 AI 处理和 WebSocket 相关的配置参数：

```python
class AppSettings(BaseSettings):
    # 现有配置...
    
    # AI 处理相关配置
    ENABLE_AI_PROCESSING: bool = True
    ROBOFLOW_API_KEY: Optional[str] = None
    ROBOFLOW_MODEL_ID: str = "next-level-i0lpn/3"
    ROBOFLOW_CONFIDENCE_THRESHOLD: float = 0.7
    
    # WebSocket 相关配置
    WEBSOCKET_PORT: int = 8765
    MAX_FPS: int = 10
```

通过这种方式，系统能够接收 RTSP 视频流、进行 AI 分析，并通过 WebSocket 将结果实时推送给客户端，满足实时盲道检测和数据传输的需求。

## **WebSocket 与 Android 客户端集成**

为了完成 Android 与服务器端的实时通信需求，本方案实现了完整的 WebSocket 通信架构，确保 AI 检测结果能够及时传递给移动端用户，从而提供实时盲道检测信息。

### **服务端 WebSocket 实现**

#### **WebSocket 路由配置**

在 FastAPI 中添加专用于 WebSocket 的端点路由：

```python
# app/api/routes.py 中添加 WebSocket 端点

from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends
from app.websockets.manager import WebSocketManager

router = APIRouter()
# WebSocket 连接管理器实例
websocket_manager = WebSocketManager()

@router.websocket("/ws/detection")
async def detection_websocket(websocket: WebSocket):
    """
    WebSocket 端点用于接收实时盲道检测结果
    """
    await websocket_manager.connect(websocket)
    try:
        # 发送初始连接确认消息
        await websocket.send_json({"status": "connected", "message": "连接成功"})
        
        # 保持连接开启，等待客户端消息
        while True:
            # 如果需要处理来自客户端的消息
            data = await websocket.receive_text()
            await websocket.send_json({"status": "received", "message": f"服务器收到: {data}"})
    except WebSocketDisconnect:
        # 处理连接断开
        websocket_manager.disconnect(websocket)
        logger.info("WebSocket 客户端断开连接")
    except Exception as e:
        logger.error(f"WebSocket 连接发生错误: {e}")
        websocket_manager.disconnect(websocket)
```

#### **WebSocket 连接管理**

为了高效地管理多个客户端连接，实现了专门的连接管理器：

```python
# app/websockets/manager.py

from fastapi import WebSocket
from typing import List, Dict, Any
import asyncio
from loguru import logger

class WebSocketManager:
    """
    WebSocket 连接管理器，用于管理多个客户端连接并广播消息
    """
    
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.connection_count: int = 0
        
    async def connect(self, websocket: WebSocket):
        """接受并存储新的 WebSocket 连接"""
        await websocket.accept()
        self.active_connections.append(websocket)
        self.connection_count += 1
        logger.info(f"新 WebSocket 客户端已连接，当前连接数: {self.connection_count}")
        
    def disconnect(self, websocket: WebSocket):
        """关闭并移除 WebSocket 连接"""
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
            self.connection_count -= 1
            logger.info(f"WebSocket 客户端已断开，当前连接数: {self.connection_count}")
    
    async def send_personal_message(self, message: Dict[str, Any], websocket: WebSocket):
        """向指定客户端发送消息"""
        try:
            await websocket.send_json(message)
        except Exception as e:
            logger.error(f"发送个人消息失败: {e}")
            self.disconnect(websocket)
    
    async def broadcast(self, message: Dict[str, Any]):
        """向所有连接的客户端广播消息"""
        disconnected_clients = []
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                logger.error(f"广播消息到客户端失败: {e}")
                disconnected_clients.append(connection)
        
        # 清理断开的连接
        for disconnected in disconnected_clients:
            self.disconnect(disconnected)
```

### **Android 端 WebSocket 集成**

Android 客户端需要实现对应的 WebSocket 客户端功能，以接收来自服务器的实时 AI 检测数据：

#### **OkHttp 的 WebSocket 实现**

使用 OkHttp 库实现高效的 WebSocket 客户端：

```kotlin
// 在 Android 应用中实现

import okhttp3.*
import okio.ByteString
import org.json.JSONObject
import java.util.concurrent.TimeUnit

class DetectionWebSocketClient(
    private val serverUrl: String,
    private val onMessageListener: (DetectionResult) -> Unit,
    private val onConnectionStatusChanged: (Boolean) -> Unit
) {
    private var webSocket: WebSocket? = null
    private val client = OkHttpClient.Builder()
        .readTimeout(30, TimeUnit.SECONDS)
        .connectTimeout(30, TimeUnit.SECONDS)
        .build()
    
    private val webSocketListener = object : WebSocketListener() {
        override fun onOpen(webSocket: WebSocket, response: Response) {
            onConnectionStatusChanged(true)
        }
        
        override fun onMessage(webSocket: WebSocket, text: String) {
            try {
                val jsonObject = JSONObject(text)
                val detectionResult = parseDetectionResult(jsonObject)
                onMessageListener(detectionResult)
            } catch (e: Exception) {
                Log.e("WebSocket", "解析消息失败", e)
            }
        }
        
        override fun onClosed(webSocket: WebSocket, code: Int, reason: String) {
            onConnectionStatusChanged(false)
        }
        
        override fun onFailure(webSocket: WebSocket, t: Throwable, response: Response?) {
            onConnectionStatusChanged(false)
            // 实现自动重连逻辑
            reconnect()
        }
    }
    
    fun connect() {
        val request = Request.Builder()
            .url("${serverUrl}/ws/detection")
            .build()
        webSocket = client.newWebSocket(request, webSocketListener)
    }
    
    fun disconnect() {
        webSocket?.close(1000, "正常关闭")
        webSocket = null
    }
    
    fun reconnect() {
        disconnect()
        // 延迟重连，避免立即重连造成的连续失败
        Handler(Looper.getMainLooper()).postDelayed({
            connect()
        }, 3000)
    }
    
    private fun parseDetectionResult(jsonObject: JSONObject): DetectionResult {
        // 解析 JSON 数据为检测结果对象
        // 实现与服务端 JSON 格式一致的解析逻辑
        return DetectionResult(
            frameId = jsonObject.optLong("frame_id"),
            timestamp = jsonObject.optLong("timestamp"),
            fps = jsonObject.optDouble("fps"),
            detections = parseDetections(jsonObject.optJSONArray("detections"))
        )
    }
    
    // 解析检测结果数组
    private fun parseDetections(jsonArray: JSONArray?): List<Detection> {
        val detections = mutableListOf<Detection>()
        jsonArray?.let {
            for (i in 0 until it.length()) {
                val item = it.optJSONObject(i)
                detections.add(
                    Detection(
                        className = item.optString("class"),
                        confidence = item.optDouble("confidence"),
                        xCenter = item.optDouble("x_center"),
                        yCenter = item.optDouble("y_center"),
                        width = item.optDouble("width"),
                        height = item.optDouble("height")
                    )
                )
            }
        }
        return detections
    }
}
```

#### **Android 客户端界面集成**

在 Android 界面中显示检测结果：

```kotlin
// MainActivity.kt

class MainActivity : AppCompatActivity() {
    private lateinit var webSocketClient: DetectionWebSocketClient
    private lateinit var videoPreview: TextureView
    private lateinit var detectionOverlay: DetectionOverlayView
    
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)
        
        videoPreview = findViewById(R.id.video_preview)
        detectionOverlay = findViewById(R.id.detection_overlay)
        
        // 初始化 RTSP 推流
        setupRtspStreaming()
        
        // 初始化 WebSocket 连接
        val serverUrl = "ws://your-server-ip:8765"
        webSocketClient = DetectionWebSocketClient(
            serverUrl = serverUrl,
            onMessageListener = { detectionResult ->
                // 更新检测结果显示
                runOnUiThread {
                    detectionOverlay.updateDetections(detectionResult.detections)
                }
            },
            onConnectionStatusChanged = { isConnected ->
                // 更新连接状态 UI
                updateConnectionStatus(isConnected)
            }
        )
    }
    
    override fun onResume() {
        super.onResume()
        // 连接 WebSocket
        webSocketClient.connect()
    }
    
    override fun onPause() {
        super.onPause()
        // 断开 WebSocket
        webSocketClient.disconnect()
    }
    
    private fun updateConnectionStatus(isConnected: Boolean) {
        // 根据连接状态更新 UI
        val statusText = findViewById<TextView>(R.id.connection_status)
        statusText.text = if (isConnected) "已连接服务器" else "未连接服务器"
        statusText.setTextColor(if (isConnected) Color.GREEN else Color.RED)
    }
}
```

### **集成测试**

为确保 WebSocket 通信的可靠性，需要进行端到端测试，包括：

1. **连接稳定性测试**：测试客户端连接、断开、重连场景
2. **数据格式一致性测试**：确保客户端和服务器端的数据结构匹配
3. **高并发测试**：模拟多客户端同时连接，验证系统稳定性
4. **网络波动测试**：测试在不稳定网络环境下的系统表现

### **WebSocket 性能优化**

为确保实时性和稳定性，采取了以下优化措施：

1. **数据压缩**：对大量数据传输场景，考虑使用 MessagePack 或 CBOR 代替 JSON 减小数据体积
2. **批量发送**：控制消息频率，合理设置发送间隔，避免消息风暴
3. **自适应帧率**：根据网络状况和客户端负载自动调整 AI 分析和消息发送频率
4. **心跳机制**：实现 ping/pong 机制，及时检测连接状态，避免连接悬挂
5. **分级日志**：对 WebSocket 通信实现详细的分级日志，便于问题排查

## **整合 RTSP 服务器与 AI 处理流程**

为了实现从 RTSP 视频流接收到 AI 分析并最终通过 WebSocket 发送结果的完整链路，本方案设计了高效的集成方案，确保各组件间平滑交互。

### **RTSP 流与 Roboflow 集成架构**

系统采用两种可选的集成架构，根据部署环境和性能需求灵活选择：

#### **方案一：直接 RTSP URL 传递**

Roboflow InferencePipeline 直接使用 RTSP URL 作为视频源：

```plaintext
RTSP 客户端 ──> RTSP 服务器 ──┐
                             │
                             │ RTSP URL
                             │
                             ▼
                     Roboflow InferencePipeline
                             │
                             │ on_prediction 回调
                             │
                             ▼
                     WebSocket 广播消息
```

此方案配置简单，实现代码如下：

```python
# 初始化 AI 处理器，直接使用 RTSP URL
ai_processor = AIProcessor(
    model_id=settings.ROBOFLOW_MODEL_ID,
    rtsp_url=f"rtsp://127.0.0.1:{settings.RTSP_PORT}{settings.RTSP_PATH}",  # 内部 RTSP URL
    on_prediction_callback=broadcast_ai_results,
    api_key=settings.ROBOFLOW_API_KEY
)
```

#### **方案二：使用 GStreamer Appsink**

通过 GStreamer 的 appsink 获取解码后的视频帧，传递给 Roboflow 处理：

```plaintext
RTSP 客户端 ──> RTSP 服务器 (GStreamer) ──> appsink 回调
                                          │
                                          │ 转换为 NumPy 数组
                                          │
                                          ▼
                                  Roboflow 处理帧
                                          │
                                          │ 推理结果
                                          │
                                          ▼
                                  WebSocket 广播消息
```

实现 appsink 回调函数，解析 GStreamer 缓冲区：

```python
def on_new_sample(sink, data):
    """处理来自 GStreamer pipeline 的新样本"""
    sample = sink.emit("pull-sample")
    if sample:
        buffer = sample.get_buffer()
        caps = sample.get_caps()
        
        # 获取视频格式信息
        structure = caps.get_structure(0)
        width = structure.get_value("width")
        height = structure.get_value("height")
        
        # 将 GStreamer 缓冲区转换为 NumPy 数组
        buffer_size = buffer.get_size()
        array_ptr = buffer.extract_dup(0, buffer_size)
        numpy_array = np.ndarray(
            shape=(height, width, 3),
            dtype=np.uint8,
            buffer=array_ptr
        )
        
        # 将帧送入处理队列
        frame_queue.put(numpy_array)
        return Gst.FlowReturn.OK
    
    return Gst.FlowReturn.ERROR
```

然后在单独线程中处理队列中的帧：

```python
def process_frames():
    """从队列获取帧并进行 AI 处理"""
    while True:
        frame = frame_queue.get()
        if frame is None:  # 结束信号
            break
            
        # 使用 Roboflow 处理帧
        result = roboflow_model.infer(frame)
        
        # 解析结果
        processed_data = parse_result(result, frame)
        
        # 通过 WebSocket 发送结果
        asyncio.run_coroutine_threadsafe(
            websocket_manager.broadcast(processed_data),
            loop
        )
```

### **系统主流程整合**

在 `app/main.py` 中，启动 RTSP 服务器、AI 处理器和 WebSocket 服务的完整逻辑：

```python
@app.on_event("startup")
async def startup_event():
    global rtsp_thread, ai_processor, periodic_task
    logger.info("应用启动中，正在初始化组件...")

    # 1. 启动 RTSP 服务器 (在单独线程中运行 GObject 主循环)
    rtsp_thread = threading.Thread(target=run_rtsp_server_loop, daemon=True)
    rtsp_thread.start()
    logger.info("RTSP 服务器启动完成")
    
    # 2. 等待 RTSP 服务器完全启动 (可以使用事件或延时)
    await asyncio.sleep(2)
    
    # 3. 启动 AI 处理器
    if settings.ENABLE_AI_PROCESSING:
        try:
            # 创建 AI 处理器实例
            ai_processor = AIProcessor(
                model_id=settings.ROBOFLOW_MODEL_ID,
                rtsp_url=f"rtsp://127.0.0.1:{settings.RTSP_PORT}{settings.RTSP_PATH}",
                on_prediction_callback=broadcast_ai_results,
                api_key=settings.ROBOFLOW_API_KEY
            )
            # 启动处理流程
            await ai_processor.start()
            logger.info(f"AI 处理器启动完成，使用模型: {settings.ROBOFLOW_MODEL_ID}")
        except Exception as e:
            logger.error(f"AI 处理器启动失败: {e}", exc_info=True)
    
    # 4. 启动定期任务 (如视频文件清理)
    periodic_task = asyncio.create_task(periodic_tasks())
    
    logger.info("所有组件启动完成，系统就绪")
```

### **AI 结果广播到 WebSocket 的实现**

定义广播函数，将 AI 处理结果发送到所有连接的客户端：

```python
# 全局 WebSocketManager 实例
websocket_manager = WebSocketManager()

async def broadcast_ai_results(prediction_data: Dict[str, Any]) -> None:
    """
    将 AI 检测结果广播到所有已连接的 WebSocket 客户端
    
    Args:
        prediction_data: 包含 AI 检测结果的字典
    """
    try:
        # 检查结果中是否有盲道检测
        has_tactile_paving = False
        if "detections" in prediction_data:
            for det in prediction_data["detections"]:
                if det.get("class") == "tactile_paving" and det.get("confidence", 0) > settings.ROBOFLOW_CONFIDENCE_THRESHOLD:
                    has_tactile_paving = True
                    break
        
        # 添加标志位，指示是否检测到盲道
        prediction_data["has_tactile_paving"] = has_tactile_paving
        
        # 添加服务器时间戳
        if "server_timestamp" not in prediction_data:
            prediction_data["server_timestamp"] = int(time.time() * 1000)
            
        # 广播消息到所有客户端
        await websocket_manager.broadcast(prediction_data)
        
        # 记录检测结果 (可选择仅在检测到目标时记录)
        if has_tactile_paving:
            logger.info(f"检测到盲道！置信度: {max([d.get('confidence', 0) for d in prediction_data['detections'] if d.get('class') == 'tactile_paving']):.2f}")
        
        # 更新监控指标
        metrics.update_detection_metrics(prediction_data)
        
    except Exception as e:
        logger.error(f"广播 AI 结果失败: {e}", exc_info=True)
```

### **启动与关闭流程**

完整的启动与关闭流程，确保所有组件能够优雅启动和关闭：

```python
@app.on_event("startup")
async def startup_event():
    # ... (之前的启动代码)
    pass

@app.on_event("shutdown")
async def shutdown_app():
    """优雅关闭所有组件"""
    logger.info("收到关闭信号，开始优雅关闭...")
    
    # 1. 关闭 AI 处理器
    if ai_processor:
        logger.info("正在停止 AI 处理器...")
        await ai_processor.stop()
    
    # 2. 停止 GObject 主循环
    if mainloop and mainloop.is_running():
        logger.info("正在停止 GObject 主循环...")
        mainloop.quit()
    
    # 3. 等待 RTSP 服务器线程结束
    if rtsp_thread and rtsp_thread.is_alive():
        logger.info("等待 RTSP 服务器线程退出...")
        rtsp_thread.join(timeout=5)  # 等待最多 5 秒
        if rtsp_thread.is_alive():
            logger.warning("RTSP 服务器线程未在超时内退出")
    
    # 4. 取消定期任务
    if periodic_task:
        logger.info("正在取消定期任务...")
        periodic_task.cancel()
        try:
            await periodic_task
        except asyncio.CancelledError:
            logger.info("定期任务已取消")
    
    # 5. 关闭所有 WebSocket 连接
    if websocket_manager and hasattr(websocket_manager, "close_all"):
        logger.info("关闭所有 WebSocket 连接...")
        await websocket_manager.close_all()
    
    logger.info("所有组件已关闭，应用退出")
```

### **性能监控与系统调优**

为确保系统在长时间运行中保持稳定性能，实现了性能监控模块：

```python
# app/services/monitor.py

import time
import threading
import psutil
import numpy as np
from typing import Dict, List, Any
from collections import deque

class PerformanceMonitor:
    """系统性能监控器，记录 CPU、内存、推理时间等指标"""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.inference_times = deque(maxlen=window_size)
        self.fps_values = deque(maxlen=window_size)
        self.memory_usage = deque(maxlen=window_size)
        self.cpu_usage = deque(maxlen=window_size)
        self.detection_counts = deque(maxlen=window_size)
        
        self.monitor_thread = None
        self.running = False
        
        # 锁用于线程安全更新
        self.lock = threading.Lock()
    
    def start(self):
        """启动性能监控线程"""
        self.running = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
    
    def stop(self):
        """停止性能监控线程"""
        self.running = False
        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=2)
    
    def _monitor_loop(self):
        """定期收集系统性能指标"""
        while self.running:
            try:
                # 收集 CPU 和内存使用情况
                cpu_percent = psutil.cpu_percent(interval=1)
                mem_info = psutil.virtual_memory()
                
                with self.lock:
                    self.cpu_usage.append(cpu_percent)
                    self.memory_usage.append(mem_info.percent)
                
            except Exception as e:
                print(f"监控异常: {e}")
            
            # 每秒收集一次系统指标
            time.sleep(1)
    
    def record_inference_time(self, duration_ms: float):
        """记录单次推理时间 (毫秒)"""
        with self.lock:
            self.inference_times.append(duration_ms)
    
    def record_fps(self, fps: float):
        """记录当前 FPS"""
        with self.lock:
            self.fps_values.append(fps)
    
    def update_detection_metrics(self, prediction_data: Dict[str, Any]):
        """根据预测结果更新检测相关指标"""
        if "fps" in prediction_data:
            self.record_fps(prediction_data["fps"])
        
        if "detections" in prediction_data:
            with self.lock:
                self.detection_counts.append(len(prediction_data["detections"]))
    
    def get_metrics(self) -> Dict[str, Any]:
        """获取汇总的性能指标"""
        with self.lock:
            avg_inference_time = np.mean(self.inference_times) if self.inference_times else 0
            avg_fps = np.mean(self.fps_values) if self.fps_values else 0
            avg_cpu = np.mean(self.cpu_usage) if self.cpu_usage else 0
            avg_mem = np.mean(self.memory_usage) if self.memory_usage else 0
            avg_detections = np.mean(self.detection_counts) if self.detection_counts else 0
            
            return {
                "avg_inference_time_ms": round(avg_inference_time, 2),
                "avg_fps": round(avg_fps, 2),
                "avg_cpu_percent": round(avg_cpu, 2),
                "avg_memory_percent": round(avg_mem, 2),
                "avg_detections_per_frame": round(avg_detections, 2),
                "samples_count": len(self.fps_values)
            }
```

在 API 路由中添加性能指标端点：

```python
# 在 app/api/routes.py 中添加

@router.get("/metrics", response_model=Dict[str, Any])
async def get_performance_metrics():
    """获取系统性能指标"""
    from app.main import performance_monitor
    
    if not performance_monitor:
        raise HTTPException(status_code=503, detail="性能监控未启用")
    
    return performance_monitor.get_metrics()
```

通过这种整合方式，系统能够高效地接收 RTSP 视频流、进行 AI 处理，并通过 WebSocket 将结果实时推送给移动客户端，同时通过监控模块确保系统性能稳定。

## **未来功能增强与优化**

随着系统的持续发展，以下是一些有价值的功能增强和优化方向：

### **AI 功能增强**

#### **1. 多模型支持**

扩展系统以支持多种 AI 模型同时运行，实现更全面的环境感知：

```python
class ModelManager:
    """管理多个 AI 模型实例"""
    
    def __init__(self):
        self.models = {}  # 模型字典: {model_name: model_instance}
        
    async def load_model(self, model_name: str, model_id: str, api_key: str = None):
        """动态加载指定的模型"""
        self.models[model_name] = AIProcessor(
            model_id=model_id,
            rtsp_url=f"rtsp://127.0.0.1:{settings.RTSP_PORT}{settings.RTSP_PATH}",
            on_prediction_callback=lambda x: self._handle_prediction(model_name, x),
            api_key=api_key or settings.ROBOFLOW_API_KEY
        )
        await self.models[model_name].start()
        
    async def _handle_prediction(self, model_name: str, prediction: Dict[str, Any]):
        """处理来自特定模型的预测结果"""
        # 添加模型源标识
        prediction["model_name"] = model_name
        
        # 发送到相应的处理逻辑
        if model_name == "tactile_paving":
            await handle_tactile_paving_prediction(prediction)
        elif model_name == "obstacle":
            await handle_obstacle_prediction(prediction)
        # ... 其他模型处理逻辑 ...
        
        # 发送综合结果
        await websocket_manager.broadcast(prediction)
```

#### **2. 模型切换与热加载**

实现模型的运行时更新与切换，无需重启服务：

```python
@router.post("/models/{model_name}/update")
async def update_model(
    model_name: str, 
    model_info: ModelUpdateRequest
):
    """动态更新或切换 AI 模型"""
    if model_name in model_manager.models:
        # 停止现有模型
        await model_manager.stop_model(model_name)
        
    # 加载新模型
    await model_manager.load_model(
        model_name=model_name,
        model_id=model_info.model_id,
        api_key=model_info.api_key
    )
    
    return {"status": "success", "message": f"模型 {model_name} 已更新为 {model_info.model_id}"}
```

#### **3. 物体追踪**

除了检测外，增加物体追踪功能，实现对盲道的持续跟踪：

```python
from supervision.tracker.byte_track import ByteTrack

class ObjectTracker:
    """使用 ByteTrack 算法跟踪检测到的物体"""
    
    def __init__(self):
        self.tracker = ByteTrack()
        
    def track(self, detections):
        """使用追踪器处理当前帧的检测结果"""
        # 转换检测格式为 tracker 需要的格式
        xyxy_boxes = []
        confidence_scores = []
        class_ids = []
        
        for det in detections:
            x_center = det["x_center"]
            y_center = det["y_center"]
            width = det["width"]
            height = det["height"]
            
            # 转换中心点坐标为左上右下坐标
            x1 = x_center - width / 2
            y1 = y_center - height / 2
            x2 = x_center + width / 2
            y2 = y_center + height / 2
            
            xyxy_boxes.append([x1, y1, x2, y2])
            confidence_scores.append(det["confidence"])
            class_ids.append(TARGET_CLASS_IDS.get(det["class"], 0))
        
        # 使用 ByteTrack 进行追踪
        detections_with_tracking = self.tracker.update(
            xyxy=np.array(xyxy_boxes),
            confidence=np.array(confidence_scores),
            class_id=np.array(class_ids)
        )
        
        # 将追踪结果合并回原始检测数据
        result = []
        for i, det in enumerate(detections):
            if i < len(detections_with_tracking.tracker_id):
                det["tracker_id"] = int(detections_with_tracking.tracker_id[i])
                result.append(det)
            else:
                result.append(det)
                
        return result
```

### **系统稳定性增强**

#### **1. 自动恢复机制**

强化系统自动恢复能力，处理各种故障场景：

```python
class SystemWatchdog:
    """系统自动恢复监视器"""
    
    def __init__(self, check_interval: int = 60):
        self.check_interval = check_interval
        self.running = False
        self.watchdog_task = None
        
    async def start(self):
        """启动监视器"""
        self.running = True
        self.watchdog_task = asyncio.create_task(self._monitor_loop())
        
    async def stop(self):
        """停止监视器"""
        self.running = False
        if self.watchdog_task:
            self.watchdog_task.cancel()
            try:
                await self.watchdog_task
            except asyncio.CancelledError:
                pass
            
    async def _monitor_loop(self):
        """定期检查系统组件状态并尝试恢复"""
        while self.running:
            try:
                # 检查 RTSP 服务器
                if not is_rtsp_server_healthy():
                    logger.warning("RTSP 服务器异常，尝试重启...")
                    await restart_rtsp_server()
                
                # 检查 AI 处理器
                if not is_ai_processor_healthy():
                    logger.warning("AI 处理器异常，尝试重启...")
                    await restart_ai_processor()
                    
                # 检查内存使用情况
                memory_info = psutil.virtual_memory()
                if memory_info.percent > 90:  # 内存使用超过 90%
                    logger.warning("内存使用率过高，执行清理...")
                    await perform_memory_cleanup()
                    
            except Exception as e:
                logger.error(f"监视器执行过程中发生错误: {e}", exc_info=True)
                
            # 等待下一次检查
            await asyncio.sleep(self.check_interval)
```

#### **2. 细粒度日志与诊断**

实现更详细的日志系统，便于问题排查：

```python
class DiagnosticLogger:
    """增强版日志记录器，支持细粒度诊断信息"""
    
    def __init__(self, log_dir: str, max_file_size_mb: int = 10):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)
        
        # 配置 loguru
        logger.remove()  # 移除默认处理器
        
        # 添加控制台处理器 (info 级别)
        logger.add(sys.stderr, level="INFO")
        
        # 添加文件处理器 (debug 级别，按大小轮转)
        logger.add(
            os.path.join(log_dir, "app.log"),
            rotation=f"{max_file_size_mb} MB",
            retention=10,
            level="DEBUG",
            backtrace=True,
            diagnose=True
        )
        
        # 单独的错误日志文件
        logger.add(
            os.path.join(log_dir, "error.log"),
            rotation=f"{max_file_size_mb} MB",
            retention=10,
            level="ERROR",
            backtrace=True,
            diagnose=True
        )
        
        # 性能日志
        logger.add(
            os.path.join(log_dir, "perf.log"),
            rotation=f"{max_file_size_mb} MB",
            filter=lambda record: "perf" in record["extra"],
            level="DEBUG"
        )
        
    def log_performance_metrics(self, metrics: Dict[str, Any]):
        """记录性能指标"""
        logger.bind(perf=True).debug(f"性能指标: {metrics}")
        
    def log_system_health(self, health_status: Dict[str, Any]):
        """记录系统健康状态"""
        if all(health_status.values()):
            logger.bind(perf=True).info("系统健康检查: 所有组件正常")
        else:
            unhealthy_components = [k for k, v in health_status.items() if not v]
            logger.warning(f"系统健康检查: 异常组件 {unhealthy_components}")
```

### **用户体验增强**

#### **1. 多通道 WebSocket**

为不同类型的数据提供专用 WebSocket 通道：

```python
# 多通道 WebSocket 路由

@router.websocket("/ws/detection")
async def detection_websocket(websocket: WebSocket):
    """用于实时检测结果的 WebSocket"""
    await websocket_managers["detection"].connect(websocket)
    try:
        # ... 处理检测数据 WebSocket 连接 ...
        pass
    except WebSocketDisconnect:
        websocket_managers["detection"].disconnect(websocket)

@router.websocket("/ws/status")
async def status_websocket(websocket: WebSocket):
    """用于系统状态更新的 WebSocket"""
    await websocket_managers["status"].connect(websocket)
    try:
        # ... 处理状态更新 WebSocket 连接 ...
        pass
    except WebSocketDisconnect:
        websocket_managers["status"].disconnect(websocket)

@router.websocket("/ws/control")
async def control_websocket(websocket: WebSocket):
    """用于接收控制命令的 WebSocket"""
    await websocket_managers["control"].connect(websocket)
    try:
        # ... 处理控制命令 WebSocket 连接 ...
        pass
    except WebSocketDisconnect:
        websocket_managers["control"].disconnect(websocket)
```

#### **2. 客户端数据过滤**

允许客户端指定所需的数据类型，减少不必要的数据传输：

```python
@router.websocket("/ws/filtered")
async def filtered_websocket(
    websocket: WebSocket,
    confidence: float = Query(0.5),
    classes: str = Query("all"),
    max_fps: float = Query(10.0)
):
    """允许客户端过滤数据的 WebSocket"""
    # 解析过滤参数
    filter_classes = classes.split(',') if classes != "all" else None
    
    # 创建客户端过滤器
    client_filter = ClientFilter(
        min_confidence=confidence,
        allowed_classes=filter_classes,
        max_fps=max_fps
    )
    
    # 连接并处理
    await websocket_manager.connect(websocket, filter=client_filter)
    try:
        # ... 处理连接 ...
        pass
    except WebSocketDisconnect:
        websocket_manager.disconnect(websocket)
```

#### **3. 管理界面**

添加 Web 管理界面，便于监控和配置系统：

```python
# 挂载静态文件服务器提供 Web 管理界面
app.mount("/admin", StaticFiles(directory="static/admin", html=True), name="admin")

# 实现管理 API
@router.get("/api/admin/status")
async def admin_status():
    """获取系统状态信息，用于管理界面"""
    return {
        "rtsp_server": {
            "running": is_rtsp_server_running(),
            "clients": rtsp_server.get_client_count() if rtsp_server else 0,
        },
        "ai_processor": {
            "running": is_ai_processor_running(),
            "model_id": settings.ROBOFLOW_MODEL_ID,
        },
        "websocket": {
            "connections": websocket_manager.connection_count,
        },
        "system": {
            "cpu": psutil.cpu_percent(),
            "memory": psutil.virtual_memory().percent,
            "uptime": get_system_uptime(),
        }
    }

@router.post("/api/admin/controls/restart/{component}")
async def admin_restart_component(component: str):
    """重启指定的系统组件"""
    if component == "rtsp":
        await restart_rtsp_server()
        return {"status": "success", "message": "RTSP 服务器已重启"}
    elif component == "ai":
        await restart_ai_processor()
        return {"status": "success", "message": "AI 处理器已重启"}
    elif component == "all":
        await restart_all_components()
        return {"status": "success", "message": "所有组件已重启"}
    else:
        raise HTTPException(status_code=400, detail=f"未知组件: {component}")
```

### **部署与扩展性增强**

#### **1. 分布式部署支持**

为满足高负载需求，实现分布式部署架构：

```plaintext
                     [负载均衡器]
                          │
              ┌───────────┼───────────┐
              │           │           │
         [实例 1]      [实例 2]     [实例 3]
              │           │           │
              └───────────┼───────────┘
                          │
                     [Redis 消息队列]
                          │
              ┌───────────┼───────────┐
              │           │           │
        [AI 节点 1]   [AI 节点 2]  [AI 节点 3]
```

实现跨实例的消息分发：

```python
class DistributedMessageBroker:
    """使用 Redis 的分布式消息代理"""
    
    def __init__(self, redis_url: str):
        self.redis = aioredis.from_url(redis_url)
        self.pubsub = self.redis.pubsub()
        
    async def publish(self, channel: str, message: Dict[str, Any]):
        """发布消息到指定通道"""
        await self.redis.publish(channel, json.dumps(message))
        
    async def subscribe(self, channel: str, callback: Callable):
        """订阅指定通道的消息"""
        await self.pubsub.subscribe(channel)
        
        # 在单独任务中处理消息
        asyncio.create_task(self._message_handler(callback))
        
    async def _message_handler(self, callback: Callable):
        """处理订阅消息"""
        while True:
            message = await self.pubsub.get_message(ignore_subscribe_messages=True)
            if message:
                try:
                    data = json.loads(message["data"])
                    await callback(data)
                except Exception as e:
                    logger.error(f"处理消息失败: {e}", exc_info=True)
            
            # 短暂等待，避免 CPU 占用过高
            await asyncio.sleep(0.01)
```

#### **2. 容器编排与自动扩缩容**

提供 Kubernetes 部署配置，支持自动扩缩容：

```yaml
# kubernetes/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rtsp-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: rtsp-server
  template:
    metadata:
      labels:
        app: rtsp-server
    spec:
      containers:
      - name: rtsp-server
        image: your-registry/rtsp-server:latest
        ports:
        - containerPort: 8000
        - containerPort: 8765
        - containerPort: 554
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        env:
        - name: ROBOFLOW_API_KEY
          valueFrom:
            secretKeyRef:
              name: rtsp-secrets
              key: roboflow-api-key
        - name: ENABLE_AI_PROCESSING
          value: "true"
        - name: DISTRIBUTED_MODE
          value: "true"
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 15
          periodSeconds: 5
```

#### **3. 边缘部署优化**

针对边缘设备优化部署配置，减少资源消耗：

```python
class EdgeOptimizedConfig(BaseConfig):
    """针对边缘设备优化的配置"""
    
    # 减少 AI 推理频率
    AI_INFERENCE_INTERVAL_MS: int = 200  # 每 200ms 推理一次，约 5 FPS
    
    # 降低分辨率处理
    VIDEO_PROCESSING_WIDTH: int = 320
    VIDEO_PROCESSING_HEIGHT: int = 240
    
    # 使用轻量级模型
    ROBOFLOW_MODEL_ID: str = "next-level-edge/1"  # 假设有针对边缘设备优化的模型版本
    
    # 最小化日志
    LOG_LEVEL: str = "WARNING"
    
    # 关闭不必要功能
    ENABLE_VIDEO_RECORDING: bool = False
    ENABLE_PERFORMANCE_METRICS: bool = False
```

通过这些未来的功能增强，系统将能够支持更复杂的应用场景，同时保持高性能和稳定性。